{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover Food Bundles ##\n",
    "\n",
    "A food confectionary is undergoing a tough time in sales and wants use machine learning to turn their fortunes around. They have captured their daily transaction data from 30th Oct 2016 to 9th Apr 2017 and want to understand what are all the food bundles that are popular among their customers. \n",
    "\n",
    "Your job is to perform <b>Market Basket Analysis</b> using the Apriori algorithm and recommend the confectionary the food bundles that they should be marketing more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Below is the list of questions you need to crack as part of this assignment </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the data from the csv file into a dataframe.\n",
    "\n",
    "2. Convert the `Datetime` object column to a datetime column and set it as index.\n",
    "\n",
    "3. Identify the top-10 best-selling and worst-selling items in the confectionary.\n",
    "\n",
    "4. Find the day and the timeslot in which most of the sales are happening in the confectionary. <b>Hint:You need to extract the hour and day details from the `Datetime` column.</b>\n",
    "\n",
    "5. Convert the data into a one-hot encoded format containing the count of items sold in a transaction. <b>Hint: You need to create the `Count` column to track the number of items sold in a transaction. You will then use the `pivot_table` method to create the one-hot encoded format.</b>\n",
    "\n",
    "6. Encode the data into 1's and 0's to apply the apriori algorithm. <b>Hint:Result obtained in the above step will contain the actual number of items sold in a transaction. In order to apply Apriori, we just need to know whether an item is present in a transaction or not. </b>\n",
    "\n",
    "7. Generate <b>frequent itemsets</b> and <b>association rules</b> with a minimum support threshold of 1% and a minimum lift value of 1. Sort them by <b>confidence values</b>.\n",
    "\n",
    "8. What <b>percentage of transactions</b> involved customers buying 'Sandwich' and 'Coffee'? <b>Hint: Select only those association rules that have lift value greater than 1 and confidence value greater than 0.5 to generate the insights.</b>\n",
    "\n",
    "9. What is the <b>probability</b> that a customer 'Coffee' given that he bought a 'Juice'?\n",
    "\n",
    "10. Which item **lifts** the Coffee's purchase by the most?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the data from the csv file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a pandas dataframe and take a look at the first 10 rows\n",
    "confec = pd.read_csv(\"confectionary.csv\")\n",
    "confec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert the `Datetime` object column to a datetime column and set it as index. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec['Datetime'] = pd.to_datetime(confec['Datetime'])\n",
    "confec = confec[[\"Datetime\", \"Transaction\", \"Item\"]].set_index(\"Datetime\")\n",
    "confec.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Identify the top-10 best-selling and worst-selling items in the confectionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the top 10 best-selling items\n",
    "confec.Item.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the bottom 10 selling items\n",
    "confec.Item.value_counts()[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Find the day and the timeslot in which most of the sales are happening in the confectionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the hour and Weekday values from the index\n",
    "confec[\"Hour\"] = confec.index.hour\n",
    "confec[\"Weekday\"] = confec.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the peak hours by grouping the item count\n",
    "confec_groupby_hour = confec.groupby(\"Hour\").agg({\"Item\": lambda item: item.count()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec_groupby_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the above result that the most sales happen between <b>11 am - 12 noon</b>. Sales actually pick up between 9 am - 4 pm and are pretty down outside these hours. Most of the sales happen during the lunch hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the most popular weekday by grouping the item count. Weekday 0 corresponds to Monday.\n",
    "confec_groupby_day = confec.groupby(\"Weekday\").agg({\"Item\": lambda item: item.count()})\n",
    "confec_groupby_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the above result that most sales happen on a <b>Saturday</b>. Weekend sales seem to be far higher than compared to weekdays. Marketing efforts are needed to boost the sales during weekdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Convert the data into a one-hot encoded format containing the count of items sold in a transaction.##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Apriori** function in the MLxtend library expects data in a one-hot encoded pandas DataFrame. This means that all the data for a transaction must be included in one row and the items must be one-hot encoded. Example below:\n",
    "\n",
    "|   | Coffee | Cake | Bread | Cookie | Muffin | Tea | Milk | Juice | Sandwich |\n",
    "|---|--------|------|-------|--------|--------|-----|------|-------|----------|\n",
    "| 0 | 0      | 1    | 1     | 0      | 0      |0    |0     |1      |0         |\n",
    "| 1 | 1      | 0    | 0     | 0      | 1      |0    |0     |0      |0         |\n",
    "| 2 | 0      | 0    | 0     | 1      | 0      |0    |0     |0      |1         |\n",
    "| 3 | 1      | 0    | 0     | 0      | 0      |1    |0     |0      |1         |\n",
    "| 4 | 1      | 1    | 0     | 0      | 0      |0    |0     |0      |0         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 'Count' column to get the number of items sold per transaction \n",
    "confec = confec.groupby([\"Transaction\",\"Item\"]).size().reset_index(name=\"Count\")\n",
    "confec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot the data into a one-hot encoded format\n",
    "confec_basket = pd.pivot_table(confec, index='Transaction', columns='Item',values='Count', fill_value=0)\n",
    "confec_basket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec_basket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** At this stage, the one-hot encoded table shows the count of items purchased as result. We just need to know whether an item is present in a transaction or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Encode the data into 1's and 0's to apply the apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the encoding function\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confec_basket_sets = confec_basket.applymap(encode_units)\n",
    "\n",
    "confec_basket_sets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the encoding function, the cell value for all the items has become either a \"1\" or a \"0\", which is what we need for the **Apriori** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7:Generate <b>frequent itemsets</b> and <b>association rules</b> with a minimum support threshold of 1% and a minimum lift value of 1. Sort them by confidence values. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(confec_basket_sets, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate association rules and sort them by confidence in ascending order\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.sort_values(\"confidence\", ascending = False, inplace = True)\n",
    "rules.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: What percentage of transactions involved customers buying 'Sandwich' and 'Coffee'?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only those rules which have lift > 1 and confidence > 0.5\n",
    "rules[ (rules['lift'] >= 1) &\n",
    "       (rules['confidence'] >= 0.5) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, you can observe that the <b>support</b> value for the association rule involving Sandwich and Coffee is 0.038. This means out of all the transactions, <b>3.8%</b> of the transactions involved customers buying Sandwich and Coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: What is the <b>probability</b> that a customer 'Coffee' given that he bought a 'Juice'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above association rule table, you can observe that the <b>confidence</b> value for the association rule involving Juice and Coffee is 0.532. This implies that whenever a customer buys Juice, there is a <b>53.2%</b> chance that he will also buy 'Coffee'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10:Which item **lifts** the Coffee's purchase by the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you observe all the association rules in the above table, you can notice that the <b>lift</b> value(1.47) is the highest for the rule having 'Toast' as the antecedent and 'Coffee' as the consequent. This implies that the purchase of <b>'Toast'</b> lifts the chances of someone buying 'Coffee' by 1.47 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
